{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304b83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,json\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a59cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hooks.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75322a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.checkpoints import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1e428560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from src.utils.train_logger import FileTrainLogger\n",
    "from src.dataio.dataset import DynamicItemDataset\n",
    "from src.dataio.batch import PaddedBatch #padded_keys\n",
    "from functools import partial\n",
    "\n",
    "logger = FileTrainLogger(\n",
    "    './log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97418de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "import torch\n",
    "\n",
    "class SimpleBrain(Brain):\n",
    "    \n",
    "    def compute_forward(self, batch, stage):\n",
    "#         print(batch.__dict__,) \n",
    "        batch = batch.to(self.device)\n",
    "#         print(batch.x_train.data.size(), batch.y_train.data.size())\n",
    "        return self.modules.model(batch.x_train.data)\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "#         print(batch.id, batch.x_train, batch.y_train)\n",
    "#         print(batch[1].size(),predictions.size())\n",
    "        \n",
    "        self.loss_metric.append(\n",
    "             batch.id, predictions, batch.y_train.data\n",
    "        )\n",
    "\n",
    "        # Compute classification error at test time\n",
    "        if stage != src.hooks.core.Stage.TRAIN:\n",
    "            self.error_metrics.append(batch.id, predictions, batch.y_train.data,)\n",
    "            \n",
    "        return torch.nn.functional.l1_loss(predictions, batch.y_train.data)\n",
    "    \n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up statistics trackers for this stage\n",
    "        self.loss_metric = utils.metric_stats.Metric(\n",
    "            metric= torch.nn.functional.l1_loss\n",
    "        )\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != src.hooks.core.Stage.TRAIN:\n",
    "            self.error_metrics = utils.metric_stats.Metric(\n",
    "            metric= torch.nn.functional.l1_loss\n",
    "        )\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"Gets called at the end of an epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
    "        stage_loss : float\n",
    "            The average loss for all of the data processed in this stage.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store the train loss until the validation stage.\n",
    "        if stage ==  src.hooks.core.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "\n",
    "        # Summarize the statistics from the stage for record-keeping.\n",
    "        else:\n",
    "            stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"error\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        # At the end of validation...\n",
    "        if stage ==  src.hooks.core.Stage.VALID:\n",
    "\n",
    "            # The train_logger writes a summary to stdout and to the logfile.\n",
    "            logger.log_stats(\n",
    "                {\"Epoch\": epoch,},\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats=stats,\n",
    "            )\n",
    "\n",
    "            # Save the current checkpoint and delete previous checkpoints,\n",
    "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"error\"])\n",
    "\n",
    "        \n",
    "            \n",
    "model = torch.nn.Linear(in_features=10, out_features=10)\n",
    "checkpoint = Checkpointer(\"./\")\n",
    "brain = SimpleBrain({\"model\": model}, opt_class=lambda x: SGD(x, 0.1),checkpointer=checkpoint)\n",
    "# brain.fit(range(1), ([torch.rand(10, 10), torch.rand(10, 10)],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4edd31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.rand(1000, 10)\n",
    "y_train  = X_train*2 + 3\n",
    "X_test = torch.rand(100, 10)\n",
    "y_test  = X_test*2 + 3\n",
    "\n",
    "data_set = {\n",
    "    i:{'x_train':k[0],'y_train':k[1]} for i,k in enumerate(zip(X_train,y_train))\n",
    "}\n",
    "val_set = {\n",
    "    i:{'x_val':k[0],'y_val':k[1]} for i,k in enumerate(zip(X_test,y_test))\n",
    "}\n",
    "\n",
    "@utils.data_pipeline.takes(\"x_train\",\"y_train\")\n",
    "@utils.data_pipeline.provides(\"x_train1\",\"y_train1\",\"double\")\n",
    "def audio_pipeline(x_train, y_train):\n",
    "    \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
    "    This is done on the CPU in the `collate_fn`.\"\"\"\n",
    "#     sig = sb.dataio.dataio.read_audio(wav)\n",
    "    return x_train+1, y_train+2, y_train *2\n",
    "\n",
    "# # Define label pipeline:\n",
    "# @sb.utils.data_pipeline.takes(\"spk_id\")\n",
    "# @sb.utils.data_pipeline.provides(\"spk_id\", \"spk_id_encoded\")\n",
    "# def label_pipeline(spk_id):\n",
    "#     yield spk_id\n",
    "#     spk_id_encoded = label_encoder.encode_label_torch(spk_id)\n",
    "#     yield spk_id_encoded\n",
    "\n",
    "# Define datasets. We also connect the dataset with the data processing\n",
    "# functions defined above.\n",
    "dataset = DynamicItemDataset(data_set, dynamic_items=[audio_pipeline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "92457115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_output_keys(['id','x_train','y_train','double'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "55f5b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'x_train': tensor([0.0540, 0.6071, 0.5121, 0.3351, 0.1700, 0.0197, 0.0611, 0.8444, 0.5856,\n",
       "         0.1174]),\n",
       " 'y_train': tensor([3.1079, 4.2142, 4.0241, 3.6702, 3.3401, 3.0395, 3.1222, 4.6888, 4.1712,\n",
       "         3.2349]),\n",
       " 'double': tensor([6.2158, 8.4283, 8.0483, 7.3405, 6.6801, 6.0790, 6.2444, 9.3777, 8.3424,\n",
       "         6.4697])}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52781112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 205.70it/s, train_loss=3.51]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 409.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [00:00<00:00, 164.43it/s, train_loss=2.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 149.72it/s, train_loss=2.4] \n",
      "100%|██████████| 32/32 [00:00<00:00, 267.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [00:00<00:00, 138.80it/s, train_loss=1.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 118.60it/s, train_loss=1.32]\n",
      "100%|██████████| 32/32 [00:00<00:00, 281.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 165.69it/s, train_loss=0.674]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 329.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "brain.fit(range(4), dataset,\n",
    "          valid_set= dataset,\n",
    "         train_loader_kwargs={'batch_size':32},\n",
    "        valid_loader_kwargs={'batch_size':32},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf43084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
